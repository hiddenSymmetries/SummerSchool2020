{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelude\n",
    "\n",
    "Numerical optimization is a big topic, and this week will cover only a few basics.  If you're intrigued enough to dig into a textbook after this, there are a few from my own shelf that I recommend:\n",
    "\n",
    "- [*Numerical Optimization*, Nocedal and Wright](https://link.springer.com/book/10.1007/978-0-387-40065-5)\n",
    "- [*Practical Optimization*, Gill, Murray, and Wright](https://doi.org/10.1137/1.9781611975604)\n",
    "- [*Nonlinear Programming*, Bertsekas](http://www.athenasc.com/nonlinbook.html)\n",
    "\n",
    "These notes are also partly adapted from a numerical analysis course that I teach that covers some numerical linear algebra, nonlinear equation solving, and optimization.  The notes (and notebooks) for the most recent offering are publicly available [here](https://www.cs.cornell.edu/courses/cs4220/2020sp/schedule.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unconstrained optimization (part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "import scipy.optimize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic setup\n",
    "\n",
    "We consider the optimization problem:\n",
    "$$\n",
    "  \\min_{x \\in \\Omega} \\phi(x)\n",
    "$$\n",
    "The function $\\phi$ is often called the objective or the cost function.\n",
    "For today, we simplify by just considering \n",
    "\n",
    "- Continuous problems ($\\Omega \\subset \\mathbb{R}^n$)\n",
    "- Smooth objectives ($\\phi \\in C^2(\\Omega)$)\n",
    "- Unconstrained continuous problems ($\\Omega = \\mathbb{R}^n$)\n",
    "\n",
    "Even with these simplifications, optimization problems can be very hard.  To see some of the types of challenges optimization algorithms can face, it is worth perusing the collections of test problems people have assembled (the [Wikipedia page](https://en.wikipedia.org/wiki/Test_functions_for_optimization) has some links and pictures).\n",
    "In general, finding a *global* minimum can be very hard even with smooth objectives, so we will focus on \n",
    "methods to find *local* minima; that is, we want $x_*$ such that $\\phi(x_*) \\leq \\phi(x)$ for all $x$ close\n",
    "enough to $x_*$.\n",
    "\n",
    "By restricting ourselves in this way, we are able to use standard calculus tools to reason about optimization.  We can characterize extrema by the first derivative test (finding *stationary points* such that $\\nabla \\phi = 0$), and we classify at lesat some optima using the second derivative test based on the Hessian matrix $H_{\\phi}$.  Calculus also gives us a lot of tools for reasoning about sensitivity to perturbations and doing local search.  The theme for today is algorithms that use a Taylor series expansion to model the objective locally, and make progress that way; tomorrow we will talk about methods that model the function by a least squares problem, or by an interpolating function instead of a Taylor expansion.\n",
    "\n",
    "In general, the more structure we have, the easier the problems are to solve numerically -- or, at least, the easier it is to analyze solution algorithms.  For example, for *convex* problems, every local minimizer is also a global minimizer, and we can generally find algorithms to converge to some minimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some model problems\n",
    "\n",
    "It is always useful to look at methods in the context of some concrete model problems.  Let's consider three such problems: a simple quadratic in 2D, a standard 2D model problem (the McCormick function), and a discretized reaction-diffusion potential function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quadratic model\n",
    "\n",
    "A general quadratic function from $\\mathbb{R}^n$ to $\\mathbb{R}$ looks like\n",
    "$$\n",
    "  \\phi(x) = c + b^T x + \\frac{1}{2} x^T A x\n",
    "$$\n",
    "where $c \\in \\mathbb{R}$, $b \\in \\mathbb{R}^n$, and $A \\in \\mathbb{R}^{n \\times n}$ with $A$ symmetric.\n",
    "The gradient is $\\nabla \\phi(x) = b + Ax$ and the Hessian is $A$.  Assuming that $A$ is nonsingular, there is exactly one stationary point (point $x_*$  where $\\nabla \\phi(x_*) = 0$), which we find by solving the linear system $Ax = -b$.\n",
    "If $A$ is positive definite, then $x_*$ is the unique global minimizer; if $A$ is negative definite, it is the maximizer; and if $A$ has both positive and negative eigenvalues, there is a saddle.\n",
    "\n",
    "For our example problem, we set $c$ and $b$ to zero, and make $A$ diagonal:\n",
    "$$\n",
    "  A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1000 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_quadratic(x):\n",
    "    \"Simple quadratic test function\"\n",
    "    return 0.5 * (x[0]**2 + 1e3 * x[1]**2)\n",
    "\n",
    "def phi_quadratic_xy(x, y):\n",
    "    \"Alternate form of phi_quadratic taking two args\"\n",
    "    return 0.5 * (x**2 + 1e3 * y**2)\n",
    "\n",
    "def dphi_quadratic(x):\n",
    "    \"Gradient of the quadratic test function\"\n",
    "    return np.array([x[0], 1e3*x[1]])\n",
    "\n",
    "def Hphi_quadratic(x):\n",
    "    \"Hessian of the quadratic test function\"\n",
    "    return np.array([[1.0, 0.0], [0.0, 1e3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A contour plot shows that there is a long, narrow valley: the function changes very rapidly with changes in $y$ relative to the variation with changes in $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quadratic():\n",
    "    \"Draw a filled contour plot of phi_quadratic\"\n",
    "    xx = np.linspace(-1, 1)\n",
    "    X, Y = np.meshgrid(xx, xx)\n",
    "    Z = phi_quadratic_xy(xx[None,:], xx[:,None])\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    cp = ax.contourf(X, Y, Z)\n",
    "    fig.colorbar(cp)\n",
    "    return fig, ax\n",
    "\n",
    "plot_quadratic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condition number of the symmetric matrix $A$ is\n",
    "$$\n",
    "  \\kappa(A) = |\\lambda_{\\max}(A) / \\lambda_{\\min}(A)|;\n",
    "$$\n",
    "this measures how long and narrow the valley is, and is important to both sensitivity of the problem and convergence properties of numerical methods.  In this case, the condition number is 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.cond(Hphi_quadratic([0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The McCormick function\n",
    "\n",
    "The McCormick function is\n",
    "$$\n",
    "  \\phi(x, y) = \\sin(x+y) + (x-y)^2 - 1.5x + 2.5y + 1.\n",
    "$$\n",
    "This function has a global minimum at around $(-0.54719, -1.54719)$, but there many local optima.\n",
    "\n",
    "The gradient and Hessian are also easy to compute, but if we are rusty on our calculus, we can also use the SymPy package to help us do the symbolic differentiation (uncomment the block below to see this in action)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Demonstrate derivative computation with SymPy\n",
    "#import sympy\n",
    "#sympy.init_printing()\n",
    "#x, y = sympy.symbols('x y')\n",
    "#phi_mccormick_sym = sympy.sin(x+y) + (x-y)**2 - 1.5*x + 2.5*y + 1\n",
    "#print(\"[{0}\\n {1}]\".format(sympy.diff(phi_mccormick_sym, x), sympy.diff(phi_mccormick_sym, y)))\n",
    "#print(\"[[{0}, {1}],\\n [{1}, {2}]]\".format(\\\n",
    "#    sympy.diff(phi_mccormick_sym, x, x), sympy.diff(phi_mccormick_sym, x, y), sympy.diff(phi_mccormick_sym, y, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_mccormick(x):\n",
    "    \"McCormick 2D test problem\"\n",
    "    return np.sin(x[0]+x[1]) + (x[0]-x[1])**2 - 1.5*x[0] + 2.5*x[1] + 1.0\n",
    "\n",
    "def phi_mccormick_xy(x, y):\n",
    "    return phi_mccormick((x, y))\n",
    "\n",
    "def dphi_mccormick(x):\n",
    "    \"Gradient of McCormick test problem\"\n",
    "    return np.array([2*x[0] - 2*x[1] + np.cos(x[0]+x[1]) - 1.5,\n",
    "                     -2*x[0] + 2*x[1] + np.cos(x[0]+x[1]) + 2.5])\n",
    "\n",
    "def Hphi_mccormick(x):\n",
    "    \"Hessian of McCormick test problem\"\n",
    "    return np.array([[2 - np.sin(x[0]+x[1]), -(np.sin(x[0]+x[1]) + 2)],\n",
    "                     [-(np.sin(x[0]+x[1]) + 2), 2 - np.sin(x[0]+x[1])]])\n",
    "\n",
    "xref_mccormick = np.array([-0.54719, -1.54719])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mccormick():\n",
    "    \"Draw a contour plot of the McCormick function on [-1.5,4]x[-3,4]\"\n",
    "    xx = np.linspace(-1.5, 4)\n",
    "    yy = np.linspace(-3, 4)\n",
    "    X, Y = np.meshgrid(xx, yy)\n",
    "    Z = phi_mccormick_xy(xx[None,:], yy[:,None])\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    cp = ax.contourf(X, Y, Z)\n",
    "    fig.colorbar(cp)\n",
    "    return fig, ax\n",
    "\n",
    "# Draw a plot and mark the reference location of the minimum\n",
    "fig, ax = plot_mccormick()\n",
    "ax.plot(xref_mccormick[0], xref_mccormick[1], 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A reaction-diffusion example\n",
    "\n",
    "The *Bratu equation* is a classic 1D PDE model from combustion theory:\n",
    "$$\\begin{align*}\n",
    "  -\\frac{d^2 u}{dx^2} - \\lambda \\exp(u) &= 0 \\\\\n",
    "  u(0) = u(1) &= 0\n",
    "\\end{align*}$$\n",
    "Solutions to the PDE correspond to stationary points of the functional:\n",
    "$$\n",
    "  \\psi[u] = \\int_{0}^1 \\left( \\frac{1}{2} u'(x)^2 - \\lambda \\exp(u) \\right) \\, du\n",
    "$$\n",
    "over the space of functions with $L^2$ derivatives satisfying the Dirichlet boundary conditions.  Stable solutions to an associated time-domain problem correspond to minimizers.\n",
    "\n",
    "We cannot compute with infinite-dimensional objects like functions and shapes, so we must discretize.  A simple way to discretize is to let $u$ be piecewise linear on a mesh with breakpoints $x_0, \\ldots, x_{N+1}$ with $x_k = kh = k/(N+1)$, and to represent $u$ by the function values at those mesh points.  With some calculus, we then have the discrete function\n",
    "$$\n",
    "  \\hat{\\psi}(u) = h \\sum_{k=1}^{N+1} \\left[ \n",
    "    \\frac{1}{2} \\left(\\frac{u_k-u_{k-1}}{h}\\right)^2 -\n",
    "    \\frac{\\lambda}{u_k-u_{k-1}} \\left(\\exp(u_k)-\\exp(u_{k-1})\\right) \\right].\n",
    "$$\n",
    "We can approximate the latter term in the sum by $\\lambda \\exp(u_k)$ (up to an $O(h)$ overall error) to get the objective function\n",
    "$$\n",
    "  \\phi(u) = h \\sum_{k=1}^{N+1} \\left[\n",
    "    \\frac{1}{2} \\left(\\frac{u_k-u_{k-1}}{h}\\right)^2 -\n",
    "    \\lambda \\exp(u_k) \\right].\n",
    "$$\n",
    "For $k = 1, \\ldots, N$, we have\n",
    "$$\n",
    "  \\frac{\\partial \\phi}{\\partial u_k} = h \\left[ \\frac{-u_{k-1} + 2u_k - u_{k+1}}{h^2} - \\lambda \\exp(u_k) \\right]\n",
    "$$\n",
    "setting these derivatives equal to zero gives the standard centered finite difference discretization of the Bratu equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_bratu(u, lam=1.0):\n",
    "    \"Compute the Bratu functional for u on a uniform mesh (u to include values at 0, 1)\"\n",
    "    phi = 0.0\n",
    "    h = 1.0 / (u.shape[0]-1)\n",
    "    for k in range(1, u.shape[0]):\n",
    "        phi += 0.5/h * (u[k]-u[k-1])**2 - lam*h * np.exp(u[k])\n",
    "    return phi\n",
    "\n",
    "def dphi_bratu(u, lam=1.0):\n",
    "    \"Gradient of phi_bratu (input on N+2 nodes, output on N)\"\n",
    "    h = 1.0 / (u.shape[0]-1)\n",
    "    return (-u[0:-2] + 2*u[1:-1] - u[2:])/h - lam*h*np.exp(u[1:-1])\n",
    "\n",
    "def Hphi_bratu(u, lam=1.0):\n",
    "    \"Sparse Hessian of phi_bratu (input on N+2 nodes, output of N-by-N)\"\n",
    "    N = u.shape[0]-2\n",
    "    h = 1.0 / (N+1)\n",
    "    Hdiags = np.zeros((3, N))\n",
    "    Hdiags[0,:] = -1.0/h\n",
    "    Hdiags[1,:] =  2.0/h - lam*h*np.exp(u[1:-1])\n",
    "    Hdiags[2,:] = -1.0/h\n",
    "    return scipy.sparse.spdiags(Hdiags, [-1, 0, 1], N, N, format='csc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bratu problem is nominally infinite-dimensional, but in practice the solution is smooth enough that it can be described quite well with a low-degree polynomial.  A not-completely-terrible approximation to the solution (at least when $\\lambda$ is not large) is\n",
    "$$\n",
    "  u(x) \\approx 4 u_{mid} x(1-x),\n",
    "$$\n",
    "for some unknown center value $u_{mid}$; and a reasonable way to estimate the behavior is to plot the function just in this direction.  Let's take advantage of this by defining a single-variable version of the Bratu optimization that only involves finding $u_{mid}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bratu_xx = np.linspace(0.0, 1.0, 202)\n",
    "bratu_vxx = 4 * bratu_xx * (1-bratu_xx)\n",
    "\n",
    "def phi_bratu_1d(umid, lam=1.0):\n",
    "    \"Evaluate the Bratu potential function for a quadratic with value umid at x = 0.5\"\n",
    "    return phi_bratu(umid * bratu_vxx, lam=lam)\n",
    "\n",
    "def dphi_bratu_1d(umid, lam=1.0):\n",
    "    \"Evaluate the derivative of phi_bratu_1d.\"\n",
    "    return np.dot(dphi_bratu(umid * bratu_vxx, lam=lam), bratu_vxx[1:-1])\n",
    "\n",
    "def Hphi_bratu_1d(umid, lam=1.0):\n",
    "    \"Evaluate the second derivative of phi_bratu_1d.\"\n",
    "    return np.dot(bratu_vxx[1:-1], Hphi_bratu(umid * bratu_vxx, lam=lam) * bratu_vxx[1:-1])\n",
    "\n",
    "umids = np.linspace(0, 5, 1001)\n",
    "phis = np.array([phi_bratu_1d(umid) for umid in umids])\n",
    "umids_min = umids[np.argmin(phis)]\n",
    "umids_max = umids[np.argmax(phis)]\n",
    "print(\"Minimum at umid = {0} (phi' = {1}, phi'' = {2})\".format(\\\n",
    "      umids_min, dphi_bratu_1d(umids_min), Hphi_bratu_1d(umids_min)))\n",
    "print(\"Maximum at umid = {0} (phi' = {1}, phi'' = {2})\".format(\\\n",
    "      umids_max, dphi_bratu_1d(umids_max), Hphi_bratu_1d(umids_max)))\n",
    "plt.plot(umids, phis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple gradient descent\n",
    "\n",
    "One of the simplest optimization algorithm is gradient descent (aka steepest descent):\n",
    "$$\n",
    "  x_{k+1} = x_k - \\alpha_k \\nabla \\phi(x_k)\n",
    "$$\n",
    "where $\\alpha_k$ is a step size parameter.  Gradient descent is motivated by a first-order Taylor approximation\n",
    "$$\n",
    "  \\phi(x_{k+1}) \\approx \\phi(x_k) + \\nabla \\phi(x_k)^T (x_{k+1}-x_k) = \\phi(x_k) - \\alpha_k \\|\\nabla \\phi(x_k)\\|^2.\n",
    "$$\n",
    "For sufficiently small $\\alpha$, gradient descent will usually make slow but steady progress, improving the function value at each step.  But when we look in detail at what is meant by \"sufficiently small\" $\\alpha$ and \"slow but steady\" progress, the basic method may be unattractive.  Let us consider, for example, the quadratic problem\n",
    "$$\n",
    "  \\phi(x) = c + b^T x + \\frac{1}{2} x^T A x.\n",
    "$$\n",
    "With a fixed step size $\\alpha$, the gradient descent iteration is\n",
    "$$\n",
    "  x_{k+1} = x_k - \\alpha (Ax_k + b) = (I-\\alpha A) x_k + b,\n",
    "$$\n",
    "and we can subtract off the stationary equation $x_* = (I-\\alpha A) x_* + b$ to get an *error iteration* for $e_k = x_k-x_*$:\n",
    "$$\n",
    "  e_{k+1} = (I-\\alpha A) e_k.\n",
    "$$\n",
    "Assuming $A$ is positive definite, the iteration converges to the unique minimum $x_*$ if $\\alpha < 1/\\lambda_{\\max}$, where $\\lambda_{\\max}$ is the largest eigenvalue of $A$.  The optimal $\\alpha$ turns out to be\n",
    "$$\n",
    "  \\alpha_* = \\frac{2}{\\lambda_{\\min} + \\lambda_{\\max}},\n",
    "$$\n",
    "which gives a worst-case error decay rate of a factor of\n",
    "$$\n",
    "  \\|e_{k+1}\\| \\leq \\left\\| 1 - \\frac{2}{1 + \\kappa(A)} \\right\\| \\|e_k\\|,\n",
    "$$\n",
    "where $\\kappa(A)$ is the condition number described above (the ratio of the largest to the smallest eigenvalue).  This type\n",
    "of convergence, where the error is cut by a constant factor at each step, is generally known as *linear* convergence.\n",
    "\n",
    "Let's see how this plays out concretely for our quadratic model problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.0, 1.0])\n",
    "alpha_opt = 2.0/1001\n",
    "xs = []\n",
    "ys = []\n",
    "errs = []\n",
    "\n",
    "for k in range(1000):\n",
    "    xs.append(x[0])\n",
    "    ys.append(x[1])\n",
    "    errs.append(np.linalg.norm(x))\n",
    "    x = x - alpha_opt * dphi_quadratic(x)\n",
    "\n",
    "plot_quadratic()\n",
    "plt.plot(xs, ys)\n",
    "plt.plot(0, 0, 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errs)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Error at step k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the long run, simple gradient descent converges on this problem when the steps are small enough.  Of course, in the long run we are all dead.  I will ask you to take my word that the Bratu problem has a similar pathology, for the same reason of poor conditioning.  Gradient descent typically only works really well for methods that are well scaled, particularly when gradients are cheap.  Clever methods that adapt the step size (e.g. the Barzilai-Borwein method) can help gradient descent converge more rapidly on a wider class of problems, but one still usually gets the best mileage from methods that choose a smarter step.  The prototypical example is the Newton iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Newton\n",
    "\n",
    "The fact that gradient descent behaves so poorly on a quadratic is particularly frustrating given that we can find the minimizer for a quadratic in closed form -- it is a simple matter of linear algebra.  If the quadratic is\n",
    "$$\n",
    "  \\phi(x) = c + b^T x + \\frac{1}{2} x^T A x,\n",
    "$$\n",
    "then the stationary point satisfies $\\nabla \\phi(x_*) = Ax_* + b = 0$, i.e. $x_* = -A^{-1} b$.  When $A$ is positive definite, as is true of $\\phi$ has a (strong) minimizer, then we can solve the linear system by Cholesky factorization of the $A$ matrix followed by two triangular solves (forward and backward substitution).  The total cost is $O(n^3)$ if $A$ has no particular structure, but we might be able to do the linear algebra faster if there is some structure.\n",
    "\n",
    "Where gradient descent makes progress by approximating the objective locally by a linear function, Newton iteration makes progress with a local quadratic approximation:\n",
    "$$\n",
    "  \\phi(x_{k} + u) \\approx \\phi(x_k) + \\nabla \\phi(x_k)^T u + \\frac{1}{2} u^T H_{\\phi}(x_k) u\n",
    "$$\n",
    "The algorithm iteratively approximates $\\phi$ by a quadratic Taylor series, then minimizes the quadratic; this gives\n",
    "$$\n",
    "  x_{k+1} = x_k - H_{\\phi}(x_k)^{-1} \\nabla \\phi(x_k).\n",
    "$$\n",
    "Where gradient descent has *linear* convergence ($\\|e_{k+1}\\| \\approx \\rho \\|e_k\\|$ for some $\\rho < 1$), under mild conditions the Newton iteration has local *quadratic* convergence, i.e. $\\|e_{k+1}\\| \\approx C \\|e_k\\|^2$.  For a linear problem, of course, Newton converges in a single step.  For nonlinear problems, Newton may take only a couple steps to converge from a good initial guess.  For the Bratu problem, for example, it only takes three iterations to reach machine precision from the quadratic\n",
    "initial guess described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Solve Bratu via Newton iteration\n",
    "u = 0.1 * bratu_vxx\n",
    "resids = []\n",
    "for k in range(10):\n",
    "    dphi_u = dphi_bratu(u)\n",
    "    resids.append(np.linalg.norm(dphi_u))\n",
    "    u[1:-1] -= scipy.sparse.linalg.spsolve(Hphi_bratu(u), dphi_u)\n",
    "\n",
    "plt.plot(resids)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Gradient norm at step k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bratu_xx.shape)\n",
    "plt.plot(bratu_xx, 0.1 * bratu_vxx, 'b--', bratu_xx, u, 'k-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens with a sloppier initial guess?  Let's consider the McCormick function and plot what Newton iteration does from a starting point of $(1, -1.5)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.0, -1.5])\n",
    "resids = []\n",
    "for k in range(10):\n",
    "    dphi_x = dphi_mccormick(x)\n",
    "    resids.append(np.linalg.norm(dphi_x))\n",
    "    x -= np.linalg.solve(Hphi_mccormick(x), dphi_x)\n",
    "\n",
    "plt.plot(resids)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convergence is pretty fast once it sets in, but it now takes a few steps.  Also, we do not land on the desired point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(np.linalg.eig(Hphi_mccormick(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So: Newton sets a high standard for fast convergence, but it has some drawbacks:\n",
    "\n",
    "- It requires lots of derivatives, and these may be a pain to derive\n",
    "- In the high-dimensional case, forming and solving systems with the Hessian matrix can be expensive\n",
    "- It can converge to a local max or saddle rather than a minimimum\n",
    "- Convergence is only local, and may require a very good initial guess\n",
    "\n",
    "We will spend the next few minutes discusssing alternative approaches that deal with these problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled gradient descent and Newton\n",
    "\n",
    "The difference between the gradient descent iteration\n",
    "$$\n",
    "  x_{k+1} = x_k - \\alpha \\nabla \\phi(x_k)\n",
    "$$\n",
    "and the Newton iteration\n",
    "$$\n",
    "  x_{k+1} = x_k - H_{\\phi}(x_k)^{-1} \\nabla \\phi(x_k)\n",
    "$$\n",
    "lies only in how we scale the gradient direction.  We can more generally consider steps of the form\n",
    "$$\n",
    "  x_{k+1} = x_k - \\alpha_k M_k^{-1} \\nabla \\phi(x_k)\n",
    "$$\n",
    "where $\\alpha_k$ is a step size and $M_k$ is a *scaling matrix*.  For $M_k = I$, we have gradient descent;\n",
    "for $M_k = H_{\\phi}(x_k)$, we have Newton.\n",
    "\n",
    "If $M_k$ is positive definite, then we can guarantee that we are at least moving in a *descent direction*; that is, Taylor's theorem gives\n",
    "$$\n",
    "  \\phi(x_{k+1}) = \\phi(x_k) - \\alpha \\nabla \\phi(x_k)^T M_k^{-1} \\nabla \\phi(x_k) + O(\\alpha^2)\n",
    "$$\n",
    "and $\\nabla \\phi(x_k)^T M_k^{-1} \\nabla \\phi(x_k) > 0$ for $\\nabla \\phi(x_k) \\neq 0$ by positive definiteness.  Therefore, Newton methods for optimization typically use $M_k = H_{\\phi}(x_k)$ when the Hessian is sufficiently positive definite, and otherwise modify the Hessian (e.g. using $M_k = H_{\\phi}(x_k) + \\lambda I$ for some $\\lambda$ sufficiently large).\n",
    "\n",
    "The scaled gradient descent framework also gives us a lot of flexibility to do things that are cheaper than taking a Newton step, or don't require as many derivatives.  For example, chord iterations \"freeze\" a Hessian for several steps, and othere methods that simply use an application-dependent scaling matrix that is not the same as the Hessian.  For the Bratu problem, simple gradient descent is extremely slow, but a simple scaling with the discrete Laplacian works reasonably well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Scaled gradient descent with line search on 1D Bratu\n",
    "\n",
    "u = 0.1 * bratu_vxx\n",
    "N = u.shape[0]-2\n",
    "h = 1.0/(N+1)\n",
    "Tdiags = np.zeros((3, N))\n",
    "Tdiags[0,:] = -1.0/h\n",
    "Tdiags[1,:] =  2.0/h\n",
    "Tdiags[2,:] = -1.0/h\n",
    "T = scipy.sparse.spdiags(Tdiags, [-1, 0, 1], N, N, format='csc')\n",
    "\n",
    "# Scaled gradient descent\n",
    "s = 1.0\n",
    "dphi_u = dphi_bratu(u)\n",
    "resids = [np.linalg.norm(dphi_u)]\n",
    "unew = np.zeros(N+2)\n",
    "for k in range(10):\n",
    "    p = -scipy.sparse.linalg.spsolve(T, dphi_u)\n",
    "    u[1:-1] += s*p\n",
    "    dphi_u = dphi_bratu(u)\n",
    "    resids.append(np.linalg.norm(dphi_u))\n",
    "    phis.append(phi_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(resids)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Gradient norm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quasi-Newton methods\n",
    "\n",
    "*Quasi-Newton* methods are Newton-like methods that build up an approximation of a Hessian over many iterations.  The most famous of these is the BFGS algorithm, which we will see in some examples later this week.  Methods like BFGS are particularly popular because they only require explicit gradients (not Hessians), but still can have the superlinear convergence seen with Newton.  Methods like limited-memory BFGS have the additional advantage that they use relatively cheap linear algebra operations (a dense factorization is not needed).\n",
    "\n",
    "BFGS is a little more complicated than the algorithms we've coded so far, so we will use the implementation in\n",
    "[SciPy's `optimize` package](https://docs.scipy.org/doc/scipy/reference/optimize.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([-1.0, 1.0])\n",
    "xs = []\n",
    "x = scipy.optimize.minimize(phi_mccormick, x0, method='BFGS', jac=dphi_mccormick, \n",
    "                            callback=lambda x: xs.append(x))\n",
    "print(x)\n",
    "plt.plot([np.linalg.norm(dphi_mccormick(x)) for x in xs])\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mccormick()\n",
    "plt.plot([x[0] for x in xs], [x[1] for x in xs], 'g')\n",
    "plt.plot(xref_mccormick[0], xref_mccormick[1], 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line search\n",
    "\n",
    "Many scaled gradient descent methods guarantee a descent direction, but one still needs to ensure that the step doesn't go too far.  We can illustrate with a one-dimensional example:\n",
    "$$\n",
    "  \\phi(x) = x \\tan^{-1}(x) - \\frac{1}{2} \\log(1+x^2).\n",
    "$$ \n",
    "The first and second derivatives of $\\phi$ are \n",
    "$$\\begin{aligned}\n",
    "  \\phi'(x) &= \\tan^{-1}(x) \\\\\n",
    "  \\phi''(x) &= \\frac{1}{1+x^2}.\n",
    "\\end{aligned}$$ \n",
    "This is about as nice a problem as one could hope for.  It is convex, with a strong global minimizer at 0.  But what happens to Newton?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_atan(x):\n",
    "    \"Test problem motivating line search\"\n",
    "    return x * np.arctan(x) - 0.5 * np.log(1 + x**2)\n",
    "\n",
    "def dphi_atan(x):\n",
    "    return np.arctan(x)\n",
    "\n",
    "def Hphi_atan(x):\n",
    "    return 1.0/(1+x**2)\n",
    "\n",
    "x = 1.4\n",
    "xs = []\n",
    "for k in range(6):\n",
    "    xs.append(x)\n",
    "    x -= dphi_atan(x) / Hphi_atan(x)\n",
    "\n",
    "xx = np.linspace(-5, 5)\n",
    "plt.plot(xx, phi_atan(xx), 'k-', \\\n",
    "         xs, [phi_atan(x) for x in xs], 'b--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, the iteration will exponentially diverge for this problem for starting points greater than about 1.3917.\n",
    "One can cook up equally benign-looking 1D functions for which Newton does other crazy things, as well, like converging to cycling between a pair of non-stationary points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamically changing the step size to ensure \"sufficient progress\" at every step us a simple approach that helps improve global convergence enormously.  The simplest such approach is a backtracking search that cuts the step length by a factor of two until one meets the condition\n",
    "$$\n",
    "  \\phi(x_{k+1}) \\leq \\phi(x_k) - \\alpha \\eta \\nabla \\phi(x_k)^T M_k^{-1} \\nabla \\phi(x_k)\n",
    "$$\n",
    "for some $\\eta < 1$ (typically a fairly small value is chosen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 10\n",
    "xs = []\n",
    "phi_x = phi_atan(x)\n",
    "for k in range(10):\n",
    "    xs.append(x)\n",
    "    p = -dphi_atan(x) / Hphi_atan(x)\n",
    "    s = 1.0\n",
    "    while phi_atan(x+s*p) > phi_x + s * 1e-2 * dphi_atan(x) * p and s > 1e-3:\n",
    "        s /= 2.0\n",
    "        print(\"Rejected step from {0} to {1}, cut to s={2}\".format(x, x+s*p, s))\n",
    "    x += s*p\n",
    "    phi_x = phi_atan(x)\n",
    "\n",
    "plt.plot([np.abs(dphi_atan(x)) for x in xs])\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity and regularization\n",
    "\n",
    "Suppose we replace a \"true\" objective $\\phi$ by some approximation $\\hat{\\phi} = \\phi + \\delta \\phi$.  Of course, the optimum function value can change by at most $\\|\\delta \\phi\\|_\\infty = \\sup_{x \\in \\Omega} |\\delta \\phi|$, but what about the location of the minimizer?  That is, if $x_*$ is a (local) minimizer for $\\phi$, what can we say about the minimizer $\\hat{x}_* = x_* + \\delta x_*$ for $\\delta \\phi$?  Formally differentiating the stationary condition $\\nabla \\phi = 0$, we have:\n",
    "$$\n",
    "  H_{\\phi}(x_*) \\, \\delta x_* + \\nabla \\delta \\phi(x_*) = 0;\n",
    "$$\n",
    "that is, the first-order change in $x_*$ is $\\delta x_* = -H_{\\phi}(x_*)^{-1} \\nabla \\delta \\phi(x_*)$.  Having just talked about Newton, you might recognize this as almost the same as a Newton step!  Thus, we expect the stationary point may be rather sensitive if the error function $\\delta \\phi$ has large gradients or if the Hessian is close to singular (or both!).\n",
    "\n",
    "One usually ought to take some care when a minimizer is very sensitive, but the type of care depends on the type of problem.  If one is solving an optimization problem in order to estimate the parameters of some model for data, a sensitive optimum means that there are several solutions that fit the data about equally well, and we need some other way of figuring out which model is \"best.\"  In this case, we usually consider add a *regularization* term.  In the case of a design problem, a very sensitive optimum may mean that there are several solutions that solve the design problem as posed at the same level, and we can ask for the solution that is best along some other axis -- minimizing cost for the same performance, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An aside on finite differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am prone to calculus errors, so I usually check myself by comparing to a finite difference approximation:\n",
    "$$\\begin{align}\n",
    "  \\nabla \\phi(x)^T u &= \\frac{\\phi(x+hu)-\\phi(x)}{h} + O(h) \\\\\n",
    "  \\nabla \\phi(x)^T u &= \\frac{\\phi(x+hu)-\\phi(x-hu)}{2h} + O(h^2).\n",
    "\\end{align}$$\n",
    "This is great for testing, as checking in a few random directions $u$ usually gives me some confidence that my\n",
    "derivatives are coded correctly.\n",
    "\n",
    "Some also like to use finite differences to estimate derivatives used in optimization schemes.  This isn't a terrible idea, but it can be expensive in terms of function evaluations.  For example, to do a gradient estimate at a point $x$ using first-order finite differences requires $n+1$ function evaluations (the one at $x$ and one for each coordinate direction).  There are also some numerical subtleties: in real computations, $h$ has to be chosen to balance truncation error (which can be estimated by manipulating Taylor series) and error in computation of the function (due to roundoff or due to use of methods like Monte Carlo).\n",
    "\n",
    "It's often worth doing the calculus by hand (or using symbolic tools like SymPy, or *automatic differentiation* as described earlier in the notebook).  Finite differencing needs to be done carefully if it is to be done at all.  Often, if derivatives are not available, it is worth considering a derivative-free method based on an interpolated polynomial model rather than using finite difference estimates.  We will talk about such derivative-free methods tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Finite difference error vs h (fixed x) for log(x) cos(x)\n",
    "\n",
    "def phi(x):\n",
    "    return np.log(x) * np.cos(x)\n",
    "\n",
    "def dphi(x):\n",
    "    return -np.log(x) * np.sin(x) + np.cos(x)/x\n",
    "\n",
    "def dphi_fd(x, h):\n",
    "    \"One-sided finite difference approx of phi'(x)\"\n",
    "    return (phi(x+h)-phi(x))/h\n",
    "\n",
    "# Plot observed vs predicted relative error in finite diff vs h\n",
    "hs = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]\n",
    "plt.plot(hs, [np.abs(dphi_fd(2.0, h)/dphi(2.0)-1.0) for h in hs])\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"h\")\n",
    "plt.ylabel(\"Relerr in fd approx of phi'(x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot observed predicted relative error in finite diff vs x for fixed h\n",
    "\n",
    "xs = np.linspace(0.01, 5)\n",
    "plt.plot(xs, [np.abs(dphi_fd(x, 1e-8)/dphi(x)-1.0) for x in xs])\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Relerr in fd approx of phi'(x)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
